{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Disaster Tweets using Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CNzeC-NYAO9tKiaq-dJuLmVxALS5VSgE",
      "authorship_tag": "ABX9TyMc8gJytf/JwsnIXsMW/ZIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imkunals726/NLP_Disaster_tweets/blob/master/NLP_Disaster_Tweets_LSTM_Glove_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7PMaX3sDSrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwRjrcwLAJcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/glove_embedding.zip\"  glove.6B.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LogjV2J0ASbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "a4c636dd-bd36-42d9-f10e-e065702739a7"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1su_J0xv7uSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "45e167e6-99b1-4e96-afb3-3439c3550383"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIk5Z3Cc8sw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_LM-1M19YMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLH8Ek279qXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "5aae4135-cf0b-4cdb-9745-5b714db1e02c"
      },
      "source": [
        "# !kaggle datasets list -s nlp-gett\n",
        "!kaggle datasets download -d misakrug/nlpgettingstarted "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading nlpgettingstarted.zip to /content\n",
            "\r  0% 0.00/593k [00:00<?, ?B/s]\n",
            "\r100% 593k/593k [00:00<00:00, 40.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ljxFkH190Xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "165dd72d-11b3-4eee-8ad1-7faa4b8971cd"
      },
      "source": [
        "!unzip nlpgettingstarted.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  nlpgettingstarted.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFSGVwyZ-qbi",
        "colab_type": "text"
      },
      "source": [
        "HELPER Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZhW6Cj3L-FF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1cc25c27-f25e-4e00-fede-864033b7660f"
      },
      "source": [
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCO4VUvCA41v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw1WzSCx-XKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = SnowballStemmer( 'english')\n",
        "\n",
        "def num_remover( val):\n",
        "    tokens = val.split()\n",
        "    nums = [ str(i) for i in range(10)]\n",
        "    final_tokens = []\n",
        "    for token in tokens:\n",
        "        token = token.strip()\n",
        "        if not any( token.startswith( num ) for num in nums):\n",
        "            final_tokens.append(token)\n",
        "    return ' '.join(final_tokens)\n",
        "\n",
        "\n",
        "def replace_urls(text):\n",
        "    tokens = text.split()\n",
        "    \n",
        "    final_tokens = []\n",
        "    \n",
        "    for token in tokens:\n",
        "        if token.lower().startswith('http'):\n",
        "            final_tokens.append('url')\n",
        "        elif token.lower().startswith('@'):\n",
        "            final_tokens.append('taggeduser')\n",
        "        else:\n",
        "            final_tokens.append(token)\n",
        "    return ' '.join(final_tokens)\n",
        "\n",
        "\n",
        "def clean_text(df):\n",
        "\n",
        "    replace_words = [ '&amp' , 'and' , '#' ]\n",
        "\n",
        "    df['text'] = df['text'].apply(replace_urls)\n",
        "\n",
        "    for word in replace_words :\n",
        "        df[ 'text' ] = df[ 'text' ].str.replace( word , '' )\n",
        "\n",
        "    df[ 'text' ] = df['text' ].apply( lambda txt : ' '.join( stemmer.stem(lemmatizer.lemmatize( word ) ) for word in txt.split( ' ') ) )\n",
        "\n",
        "    df['keyword'] = df['keyword'].fillna('').str.replace('%20' , ' ')\n",
        "    df[ 'text' ] = df.apply( lambda row : str( row[ 'text' ] ) + ' ' + str(row[ 'keyword' ]) if row[ 'keyword' ] else row[ 'text' ] , axis = 1)\n",
        "\n",
        "    df['text'] = df['text'].apply(num_remover)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tcW4WYQ-wYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "38fe7737-eca1-4285-d5cd-81a77958d106"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM9-qstD_Gf0",
        "colab_type": "text"
      },
      "source": [
        "Lets Clean the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rif4GKZq_Tsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW59is84-_lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "c2961870-260b-4869-d63e-700430315bf5"
      },
      "source": [
        "\n",
        "# train_df = clean_text(train_df)\n",
        "train_df['text_sequences'] = train_df['text'].apply(keras.preprocessing.text.text_to_word_sequence)\n",
        "train_df['text_sequences'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [our, deeds, are, the, reason, of, this, earth...\n",
              "1        [forest, fire, near, la, ronge, sask, canada]\n",
              "2    [all, residents, asked, to, 'shelter, in, plac...\n",
              "3    [13, 000, people, receive, wildfires, evacuati...\n",
              "4    [just, got, sent, this, photo, from, ruby, ala...\n",
              "Name: text_sequences, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urk9EN9f5iIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD4D_emZ8MfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucZaUYsY8ezt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.6B.200d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQc8E3_29GCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ba5b5833-5f90-4c54-ccb2-110b4e070fc3"
      },
      "source": [
        "len(embeddings_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ZYrhiN9wLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = {key:idx for idx,key in enumerate(embeddings_index.keys())}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoOyky7DVAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA0r2fLy-X1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "train_df['text_sequences'] = train_df['text'].apply(keras.preprocessing.text.text_to_word_sequence)\n",
        "\n",
        "def get_sequence(text_sequence):\n",
        "  sequence = []\n",
        "  for word in text_sequence:\n",
        "    if word in word_index:\n",
        "      sequence.append(word_index[word])\n",
        "    else:\n",
        "      sequence.append(len(word_index))\n",
        "  return sequence\n",
        "train_df['sequence'] = train_df['text_sequences'].apply(get_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEd6jXFaE1Dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "255282da-7e2d-4f43-8e9b-6235a07dcb43"
      },
      "source": [
        "\n",
        "train_df[['text_sequences' , 'sequence']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_sequences</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "      <td>[162, 13091, 32, 0, 1247, 3, 37, 3117, 107, 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[2061, 484, 355, 1047, 159475, 270969, 774]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[all, residents, asked, to, 'shelter, in, plac...</td>\n",
              "      <td>[64, 1048, 476, 4, 400000, 6, 400000, 32, 134,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[13, 000, people, receive, wildfires, evacuati...</td>\n",
              "      <td>[676, 14077, 69, 1653, 18161, 6904, 1949, 6, 628]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "      <td>[120, 405, 688, 37, 3119, 25, 12650, 4604, 19,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      text_sequences                                           sequence\n",
              "0  [our, deeds, are, the, reason, of, this, earth...  [162, 13091, 32, 0, 1247, 3, 37, 3117, 107, 14...\n",
              "1      [forest, fire, near, la, ronge, sask, canada]        [2061, 484, 355, 1047, 159475, 270969, 774]\n",
              "2  [all, residents, asked, to, 'shelter, in, plac...  [64, 1048, 476, 4, 400000, 6, 400000, 32, 134,...\n",
              "3  [13, 000, people, receive, wildfires, evacuati...  [676, 14077, 69, 1653, 18161, 6904, 1949, 6, 628]\n",
              "4  [just, got, sent, this, photo, from, ruby, ala...  [120, 405, 688, 37, 3119, 25, 12650, 4604, 19,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiIqsWZL_RPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection  import train_test_split\n",
        "X_train, X_val , y_train, y_val = train_test_split(train_df[['text']] , train_df['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rucpa9O6AIk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3orGdKUg_cUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(word_index)+1\n",
        "embedding_dim = 200\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lly-cBEpC1_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(sequences_to_pad):\n",
        "  # word_index = tokenizer.word_index\n",
        "  # training_sequences = tokenizer.texts_to_sequences(sentences_to_convert)\n",
        "  sequences_to_pad = sequences_to_pad.apply(keras.preprocessing.text.text_to_word_sequence)\n",
        "  sequences_to_pad = sequences_to_pad.apply(get_sequence)\n",
        "  training_padded = pad_sequences(sequences_to_pad, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "  return training_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLtdFdYABc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPtEqQNg_2cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_text = X_train['text']\n",
        "\n",
        "\n",
        "testing_text = X_val['text']\n",
        "\n",
        "training_padded = prepare_data(training_text)\n",
        "testing_padded = prepare_data(testing_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDtqnIWIAaK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76MwOuX_AvNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length=max_length, trainable=False),\n",
        "\n",
        "      tf.keras.layers.LSTM(units = 128, return_sequences=True),\n",
        "      tf.keras.layers.Dropout(0.5),      \n",
        "      tf.keras.layers.LSTM(units = 128, return_sequences=True),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.LSTM(units = 128, return_sequences=True),\n",
        "      tf.keras.layers.Dropout(0.5),      \n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "      tf.keras.layers.Dense(128,activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),      \n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkSsGaHlA0By",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "de25d0ee-d2ec-482e-b345-b4b42ea7db9c"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 100, 200)          80000200  \n",
            "_________________________________________________________________\n",
            "lstm_33 (LSTM)               (None, 100, 128)          168448    \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_34 (LSTM)               (None, 100, 128)          131584    \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, 100, 128)          131584    \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_14  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 80,448,457\n",
            "Trainable params: 448,257\n",
            "Non-trainable params: 80,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9YfREWhA_00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "05340e01-9baf-414d-82d8-d51eaf9dd430"
      },
      "source": [
        "num_epochs = 2\n",
        "history = model.fit(training_padded, y_train, epochs=num_epochs, validation_data=(testing_padded, y_val), verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxygdajAvtt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4411vFjDRUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "edbc6400-ab3b-4b25-d026-137d6ec3ef68"
      },
      "source": [
        "xtf.keras.backend.set_value(model.optimizer.lr,0.01)\n",
        "num_epochs = 10\n",
        "history = model.fit(training_padded, y_train, epochs=num_epochs, validation_data=(testing_padded, y_val), verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "179/179 - 4s - loss: 0.6836 - accuracy: 0.5710 - val_loss: 0.6848 - val_accuracy: 0.5683\n",
            "Epoch 2/10\n",
            "179/179 - 4s - loss: 0.6834 - accuracy: 0.5710 - val_loss: 0.6844 - val_accuracy: 0.5683\n",
            "Epoch 3/10\n",
            "179/179 - 4s - loss: 0.6836 - accuracy: 0.5710 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
            "Epoch 4/10\n",
            "179/179 - 4s - loss: 0.6835 - accuracy: 0.5710 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
            "Epoch 5/10\n",
            "179/179 - 4s - loss: 0.6835 - accuracy: 0.5710 - val_loss: 0.6844 - val_accuracy: 0.5683\n",
            "Epoch 6/10\n",
            "179/179 - 4s - loss: 0.6832 - accuracy: 0.5710 - val_loss: 0.6845 - val_accuracy: 0.5683\n",
            "Epoch 7/10\n",
            "179/179 - 4s - loss: 0.6834 - accuracy: 0.5710 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
            "Epoch 8/10\n",
            "179/179 - 4s - loss: 0.6835 - accuracy: 0.5710 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
            "Epoch 9/10\n",
            "179/179 - 4s - loss: 0.6832 - accuracy: 0.5710 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
            "Epoch 10/10\n",
            "179/179 - 4s - loss: 0.6833 - accuracy: 0.5710 - val_loss: 0.6841 - val_accuracy: 0.5683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMdTA996BTDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIb3SrueBmLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_df = clean_text(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzPFwYVsEaKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = clean_text(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbThfHkABov4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_df['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20N2k-9pDW6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_padded = prepare_data(train_df['text'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxL8MjcUDdgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_padded = prepare_data(test_df['text'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65g00-_eDloW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8agCibgEASX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "743b1024-0e96-499f-e25e-0981b553598f"
      },
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(training_padded, train_df['target'], epochs=num_epochs, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "238/238 - 11s - loss: 0.5884 - accuracy: 0.7081\n",
            "Epoch 2/10\n",
            "238/238 - 11s - loss: 0.5251 - accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "238/238 - 10s - loss: 0.4906 - accuracy: 0.7872\n",
            "Epoch 4/10\n",
            "238/238 - 10s - loss: 0.4344 - accuracy: 0.8124\n",
            "Epoch 5/10\n",
            "238/238 - 10s - loss: 0.4138 - accuracy: 0.8236\n",
            "Epoch 6/10\n",
            "238/238 - 10s - loss: 0.3986 - accuracy: 0.8333\n",
            "Epoch 7/10\n",
            "238/238 - 10s - loss: 0.3796 - accuracy: 0.8401\n",
            "Epoch 8/10\n",
            "238/238 - 10s - loss: 0.3651 - accuracy: 0.8521\n",
            "Epoch 9/10\n",
            "238/238 - 9s - loss: 0.3436 - accuracy: 0.8643\n",
            "Epoch 10/10\n",
            "238/238 - 9s - loss: 0.3208 - accuracy: 0.8719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKGXdzvGtgzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "fe2bc720-286d-4ff4-ea54-97f41c811a8c"
      },
      "source": [
        "history1 = model.fit(training_padded, train_df['target'], epochs=5, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "238/238 - 10s - loss: 0.2947 - accuracy: 0.8841\n",
            "Epoch 2/5\n",
            "238/238 - 10s - loss: 0.2671 - accuracy: 0.8990\n",
            "Epoch 3/5\n",
            "238/238 - 10s - loss: 0.2515 - accuracy: 0.9050\n",
            "Epoch 4/5\n",
            "238/238 - 10s - loss: 0.2173 - accuracy: 0.9232\n",
            "Epoch 5/5\n",
            "238/238 - 10s - loss: 0.1937 - accuracy: 0.9308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH3qSgIKELb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(testing_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZesNu3o_FCQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " results = (results > 0.5).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVJZ7Y7IFDgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "77902536-7898-4d7b-a61e-08a030d61517"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvLsLHLAt0DI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdac6277-cbee-4fe5-fd41-d9d19d9ef31b"
      },
      "source": [
        "test_df.head(1)['text'].tolist()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Just happened a terrible car crash'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hibC7UZYFN86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['target'] = results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONpcXqQxFScM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fcc936e8-ecc1-41ae-ee34-46df665bb367"
      },
      "source": [
        "test_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XThQWuPCFUWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "119a39a1-bf8d-402a-8ddf-bd6bc14c4e33"
      },
      "source": [
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       0\n",
              "1   2       0\n",
              "2   3       0\n",
              "3   9       0\n",
              "4  11       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jdfQdDLFacm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = test_df[['id' , 'target']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1aiDJa0FiFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('using_embeddings_and_lstm_1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd9C-EM4FsyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}